---
description:
globs:
alwaysApply: false
---
# Reasoning Models Integration Guide

This guide covers the implementation patterns and best practices for working with reasoning-capable AI models in Warden, including OpenAI's o1/o3 series, DeepSeek's reasoning models, and Perplexity's reasoning-capable models.

## Supported Reasoning Models

### Model List
Reasoning models are centrally defined in [AppConstants.swift](mdc:Warden/Configuration/AppConstants.swift):
- **OpenAI**: o1, o1-preview, o1-mini, o3-mini, o3-mini-high, o3-mini-2025-01-31
- **DeepSeek**: deepseek-reasoner
- **Perplexity**: sonar-reasoning-pro, sonar-reasoning
- **OpenRouter**: Access to reasoning models through proxy

### Model Detection
```swift
// Check if a model supports reasoning
let isReasoningModel = AppConstants.openAiReasoningModels.contains(modelId)
```

## Implementation Patterns

### System Message Handling
Reasoning models don't support the "system" role. Convert system messages to user messages:

```swift
if !AppConstants.openAiReasoningModels.contains(chat.gptModel) {
    messages.append(["role": "system", "content": systemMessage])
} else {
    messages.append(["role": "user", "content": "Take this message as the system message: \(systemMessage)"])
}
```

### Response Processing
Reasoning models provide both reasoning content and final answer content:

#### DeepSeek Pattern
```swift
// Handle reasoning content if available
if let reasoningContent = message["reasoning_content"] as? String {
    finalContent = "<think>\n\(reasoningContent)\n</think>\n\n\(messageContent)"
}
```

#### OpenRouter Pattern
```swift
// Handle reasoning content if available
if let reasoningContent = message["reasoning"] as? String {
    finalContent = "<think>\n\(reasoningContent)\n</think>\n\n\(messageContent)"
}
```

### Streaming Implementation
Handle separate reasoning and content streams:

```swift
if let reasoningContent = delta["reasoning_content"] as? String {
    return (finished, nil, reasoningContent, "reasoning")
} else if let content = delta["content"] as? String {
    return (finished, nil, content, defaultRole)
}
```

## UI Integration

### Thinking Process Display
Use [ThinkingProcessView.swift](mdc:Warden/UI/Chat/ThinkingProcessView.swift) for collapsible reasoning display:

```swift
struct ThinkingProcessView: View {
    let content: String
    @State private var isExpanded: Bool = true
    
    var body: some View {
        VStack(alignment: .leading, spacing: 8) {
            Button(action: { isExpanded.toggle() }) {
                HStack {
                    Text("Reasoning")
                    Image(systemName: isExpanded ? "chevron.down" : "chevron.right")
                    Spacer()
                }
            }
            
            if isExpanded {
                Text(content)
                    .foregroundColor(.gray)
                    .textSelection(.enabled)
            }
        }
    }
}
```

### Model Identification
Visual indicators for reasoning models in [ModelSelectorDropdown.swift](mdc:Warden/UI/Components/ModelSelectorDropdown.swift):

```swift
private var isReasoningModel: Bool {
    AppConstants.openAiReasoningModels.contains(model.id)
}

private var isThinkingModel: Bool {
    model.id.lowercased().contains("thinking") || isReasoningModel
}
```

### Stream Management
Handle reasoning and content streams differently:

```swift
if role == "reasoning" {
    if !isInReasoningBlock {
        isInReasoningBlock = true
        continuation.yield("<think>\n")
    }
    continuation.yield(messageData)
} else {
    if isInReasoningBlock {
        isInReasoningBlock = false
        continuation.yield("\n</think>\n\n")
    }
    continuation.yield(messageData)
}
```

## Content Format Standards

### Thinking Tags
Use standardized format for reasoning content:
- Opening: `<think>`
- Content: Raw reasoning text
- Closing: `</think>`
- Separator: Double newline before actual response

### Example Output Format
```
<think>
Let me think about this step by step...
1. First, I need to understand the problem
2. Then, I'll consider different approaches
3. Finally, I'll choose the best solution
</think>

Based on my analysis, here's the answer...
```

## Best Practices

### Handler Implementation
1. **Check Model Type**: Always verify if model supports reasoning before special processing
2. **Graceful Fallback**: Handle cases where reasoning content is missing
3. **Stream State**: Maintain proper state for reasoning vs content streams
4. **Error Handling**: Handle incomplete reasoning streams gracefully

### UI Considerations
1. **Collapsible Display**: Make reasoning content collapsible by default
2. **Visual Distinction**: Use different styling for reasoning vs final content
3. **Performance**: Don't render large reasoning blocks if collapsed
4. **Accessibility**: Ensure reasoning content is accessible to screen readers

### Content Processing
1. **Tag Preservation**: Maintain `<think>` tags for proper UI rendering
2. **Stream Buffering**: Buffer reasoning content before displaying
3. **Memory Management**: Clean up reasoning content buffers appropriately
4. **Search Integration**: Index both reasoning and final content for Spotlight

## Testing Patterns

### Mock Reasoning Content
```swift
let mockReasoningResponse = """
<think>
This is a test reasoning process...
</think>

This is the final answer.
"""
```

### Handler Testing
1. Test with and without reasoning content
2. Verify proper stream handling
3. Check UI state transitions
4. Validate content formatting

## Troubleshooting

### Common Issues
1. **Missing Reasoning**: Some models may not always provide reasoning content
2. **Stream Interruption**: Handle cases where reasoning stream is cut off
3. **Format Inconsistency**: Different providers use different reasoning field names
4. **UI State**: Ensure proper state management for expandable reasoning sections

### Debug Strategies
1. **Logging**: Log reasoning content parsing (without exposing API keys)
2. **Stream Monitoring**: Monitor separate reasoning and content streams
3. **UI Testing**: Test with various reasoning content lengths
4. **Model Switching**: Test behavior when switching between reasoning and non-reasoning models
