---
description: 
globs: 
alwaysApply: true
---
# AI Service Integration Guide

Warden supports multiple AI providers through a unified API abstraction layer. This guide covers integration patterns and best practices.

## Supported AI Providers
- **OpenAI**: ChatGPT models (gpt-4o, o1-mini, o1-preview, o3-mini, etc.)
- **Anthropic**: Claude models
- **Google**: Gemini models
- **xAI**: Grok models
- **Perplexity**: Various models including reasoning-capable models
- **DeepSeek**: Chat and reasoning models (deepseek-chat, deepseek-reasoner)
- **Groq**: High-speed inference models
- **OpenRouter**: 50+ models including reasoning models
- **Ollama**: Local LLM support
- **Mistral**: Mistral AI models
- **Custom**: Any OpenAI-compatible API

## Core Components

### Configuration
- **API Services**: Configured in [AppConstants.swift](mdc:Warden/Configuration/AppConstants.swift)
- **Model Definitions**: Default models and parameters defined per service
- **Authentication**: API keys stored securely in user preferences
- **Reasoning Models**: Special handling for o1/o3 models and reasoning-capable models

### Data Models
- **Message Structure**: Defined in [Models.swift](mdc:Warden/Models/Models.swift) and [MessageContent.swift](mdc:Warden/Models/MessageContent.swift)
- **Request Transformation**: [RequestMessagesTransformer.swift](mdc:Warden/Models/RequestMessagesTransformer.swift) handles API format conversion
- **Image Support**: [ImageAttachment.swift](mdc:Warden/Models/ImageAttachment.swift) manages multimodal content

### API Integration Patterns
- **Streaming Responses**: Real-time message streaming for better UX
- **Reasoning Support**: Special handling for thinking process display via [ThinkingProcessView.swift](mdc:Warden/UI/Chat/ThinkingProcessView.swift)
- **Error Handling**: Graceful degradation and user-friendly error messages
- **Rate Limiting**: Respect API provider limits and quotas
- **Context Management**: Intelligent conversation context sizing

## Reasoning Models Integration

### Supported Reasoning Models
- **OpenAI**: o1, o1-preview, o1-mini, o3-mini, o3-mini-high, o3-mini-2025-01-31
- **DeepSeek**: deepseek-reasoner with reasoning content support
- **Perplexity**: sonar-reasoning-pro, sonar-reasoning
- **OpenRouter**: Access to reasoning models through proxy

### Implementation Patterns
- **System Message Handling**: Reasoning models don't support system role - convert to user message
- **Reasoning Content**: Parse and display thinking process in expandable UI
- **Temperature Override**: Some reasoning models may ignore temperature settings
- **Streaming Processing**: Handle reasoning and content streams separately

### Handler Implementation for Reasoning
```swift
// Example from DeepseekHandler.swift
if let reasoningContent = message["reasoning_content"] as? String {
    finalContent = "<think>\n\(reasoningContent)\n</think>\n\n\(messageContent)"
}
```

## AI Personas System
- **System Instructions**: Customizable per persona and per chat
- **Temperature Control**: Adjustable creativity/randomness settings
- **Model Selection**: Per-persona default model configuration
- **Inheritance**: Chat-level overrides of persona settings
- **Reasoning Model Compatibility**: Automatic system message conversion for reasoning models

## Message Processing
- **Content Types**: Text, code, images, tables, LaTeX equations
- **Syntax Highlighting**: Code block detection and formatting
- **Interactive Previews**: HTML/CSS/JavaScript execution
- **Thinking Process**: Collapsible reasoning display for thinking-capable models
- **Export Capabilities**: CSV/JSON export for structured data

## Search and Indexing
- **Spotlight Integration**: [SpotlightIndexManager.swift](mdc:Warden/Utilities/SpotlightIndexManager.swift) enables macOS Spotlight search
- **Automatic Indexing**: Chat content automatically indexed for search
- **Index Management**: Rebuild and clear operations available in preferences
- **Performance**: Optimized indexing with content limits and background processing

## Local LLM Support (Ollama)
- **Installation**: Automatic detection of Ollama service
- **Model Management**: Pull and manage local models
- **Performance**: Optimized for Apple Silicon Macs
- **Privacy**: Complete local processing without external API calls

## Best Practices
- **API Key Security**: Never log or expose API keys
- **Graceful Failures**: Always provide fallback options
- **User Feedback**: Clear status indicators for API calls
- **Resource Management**: Proper cleanup of streaming connections
- **Reasoning Model Handling**: Check for reasoning capability before special processing
- **Testing**: Mock API responses for development and testing
- **Spotlight Integration**: Automatically index new chats and messages for searchability
