---
description: 
globs: 
alwaysApply: true
---
# AI Service Integration Guide

Warden supports multiple AI providers through a unified API abstraction layer. This guide covers integration patterns and best practices.

## Supported AI Providers
- **OpenAI**: ChatGPT models (gpt-4o, o1-mini, o1-preview, etc.)
- **Anthropic**: Claude models
- **Google**: Gemini models
- **xAI**: Grok models
- **Perplexity**: Various models
- **OpenRouter**: 50+ models
- **Ollama**: Local LLM support
- **Custom**: Any OpenAI-compatible API

## Core Components

### Configuration
- **API Services**: Configured in [AppConstants.swift](mdc:Warden/Configuration/AppConstants.swift)
- **Model Definitions**: Default models and parameters defined per service
- **Authentication**: API keys stored securely in user preferences

### Data Models
- **Message Structure**: Defined in [Models.swift](mdc:Warden/Models/Models.swift) and [MessageContent.swift](mdc:Warden/Models/MessageContent.swift)
- **Request Transformation**: [RequestMessagesTransformer.swift](mdc:Warden/Models/RequestMessagesTransformer.swift) handles API format conversion
- **Image Support**: [ImageAttachment.swift](mdc:Warden/Models/ImageAttachment.swift) manages multimodal content

### API Integration Patterns
- **Streaming Responses**: Real-time message streaming for better UX
- **Error Handling**: Graceful degradation and user-friendly error messages
- **Rate Limiting**: Respect API provider limits and quotas
- **Context Management**: Intelligent conversation context sizing

## AI Personas System
- **System Instructions**: Customizable per persona and per chat
- **Temperature Control**: Adjustable creativity/randomness settings
- **Model Selection**: Per-persona default model configuration
- **Inheritance**: Chat-level overrides of persona settings

## Message Processing
- **Content Types**: Text, code, images, tables, LaTeX equations
- **Syntax Highlighting**: Code block detection and formatting
- **Interactive Previews**: HTML/CSS/JavaScript execution
- **Export Capabilities**: CSV/JSON export for structured data

## Local LLM Support (Ollama)
- **Installation**: Automatic detection of Ollama service
- **Model Management**: Pull and manage local models
- **Performance**: Optimized for Apple Silicon Macs
- **Privacy**: Complete local processing without external API calls

## Best Practices
- **API Key Security**: Never log or expose API keys
- **Graceful Failures**: Always provide fallback options
- **User Feedback**: Clear status indicators for API calls
- **Resource Management**: Proper cleanup of streaming connections
- **Testing**: Mock API responses for development and testing
